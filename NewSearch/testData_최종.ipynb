{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3ed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,json\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as pc\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6370210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fc625ec",
   "metadata": {},
   "source": [
    "### 테스트 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9242eb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153709120</td>\n",
       "      <td>갤럭시 중고폰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153709376</td>\n",
       "      <td>연예인 지갑 지갑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153710656</td>\n",
       "      <td>갤럭시s10 갤럭시북 NT950XDZ-G58AW 중고폰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                            name\n",
       "0  153709120                         갤럭시 중고폰\n",
       "1  153709376                       연예인 지갑 지갑\n",
       "2  153710656  갤럭시s10 갤럭시북 NT950XDZ-G58AW 중고폰"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tmp_data = [[153709120,'갤럭시 중고폰'],[153709376,'연예인 지갑 지갑'],[153710656,'갤럭시s10 갤럭시북 NT950XDZ-G58AW 중고폰']]\n",
    "tmp = pd.DataFrame(tmp_data, columns=['id','name'])\n",
    "\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f7a9f",
   "metadata": {},
   "source": [
    "## 1. 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61658eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data):\n",
    "    token=[]\n",
    "\n",
    "    data = data.lower() #소문자로 변환\n",
    "    words = data.split() #공백으로 분리\n",
    "    #print(\"split \", words)\n",
    "\n",
    "    #규칙에 해당 -> findall\n",
    "    p = re.compile(\"[가-힣]+|[ㄱ-ㅎ|ㅏ-ㅣ]+|[a-z0-9-]+|[^ a-z0-9가-힣+]\") #규칙\n",
    "\n",
    "    for word in words:\n",
    "        find = re.findall(p,word)\n",
    "        for w in find:\n",
    "            #token=token+w+' '\n",
    "            token.append(w)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77f13a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153709120</td>\n",
       "      <td>갤럭시 중고폰</td>\n",
       "      <td>[갤럭시, 중고폰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153709376</td>\n",
       "      <td>연예인 지갑 지갑</td>\n",
       "      <td>[연예인, 지갑, 지갑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153710656</td>\n",
       "      <td>갤럭시s10 갤럭시북 NT950XDZ-G58AW 중고폰</td>\n",
       "      <td>[갤럭시, s10, 갤럭시북, nt950xdz-g58aw, 중고폰]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                            name  \\\n",
       "0  153709120                         갤럭시 중고폰   \n",
       "1  153709376                       연예인 지갑 지갑   \n",
       "2  153710656  갤럭시s10 갤럭시북 NT950XDZ-G58AW 중고폰   \n",
       "\n",
       "                                   token  \n",
       "0                             [갤럭시, 중고폰]  \n",
       "1                          [연예인, 지갑, 지갑]  \n",
       "2  [갤럭시, s10, 갤럭시북, nt950xdz-g58aw, 중고폰]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['token']=tmp['name'].apply(tokenizer)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d46fda",
   "metadata": {},
   "source": [
    "## 2.inverted index -> 파일(.parquet)생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd75e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 153709120, 'name': '갤럭시 중고폰', 'token': ['갤럭시', '중고폰']},\n",
       " {'id': 153709376, 'name': '연예인 지갑 지갑', 'token': ['연예인', '지갑', '지갑']},\n",
       " {'id': 153710656,\n",
       "  'name': '갤럭시s10 갤럭시북 NT950XDZ-G58AW 중고폰',\n",
       "  'token': ['갤럭시', 's10', '갤럭시북', 'nt950xdz-g58aw', '중고폰']}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js = tmp.to_json(orient = 'records')\n",
    "json_data =json.loads(js)\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0aac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'갤럭시': [153709120, 153710656], '중고폰': [153709120, 153710656], '연예인': [153709376], '지갑': [153709376, 153709376], 's10': [153710656], '갤럭시북': [153710656], 'nt950xdz-g58aw': [153710656]})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index_dict=defaultdict(list)\n",
    "\n",
    "for data in json_data:\n",
    "    for token in data['token']:\n",
    "            index_dict[token].append(data['id'])\n",
    "\n",
    "print(index_dict)\n",
    "\n",
    "p=pd.DataFrame(list(index_dict.items()),columns=['token', 'docu_list'])\n",
    "#p=p.set_index('token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8015831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(p)\n",
    "pq.write_table(table, 'example.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00333ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>docu_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>갤럭시</td>\n",
       "      <td>[153709120, 153710656]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>중고폰</td>\n",
       "      <td>[153709120, 153710656]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>연예인</td>\n",
       "      <td>[153709376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지갑</td>\n",
       "      <td>[153709376, 153709376]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s10</td>\n",
       "      <td>[153710656]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token               docu_list\n",
       "0   갤럭시  [153709120, 153710656]\n",
       "1   중고폰  [153709120, 153710656]\n",
       "2   연예인             [153709376]\n",
       "3    지갑  [153709376, 153709376]\n",
       "4   s10             [153710656]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df = pq.read_table('example.parquet').to_pandas()\n",
    "index_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30983d",
   "metadata": {},
   "source": [
    "## 3.tf-idf 적용 (TfidfVectorizer ) -> 파일(.parquet)생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42369bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_7464/3369141956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m## all_teokn = tmp['token ] : list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvect2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtfvect_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtfvect_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "## token 많아질수록 벡터의 차원이 커지는 문제\n",
    "## 가장 많이 나온 단어 n개만 사용하는 max_features 파라미터 : TfidfVectorizer(max_features=4)\n",
    "## all_teokn = tmp['token ] : list\n",
    "\n",
    "vect2 = TfidfVectorizer(tokenizer=tf_tokenizer)\n",
    "tfvect_matrix = vect2.fit_transform(tmp['name'])\n",
    "tfvect_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvect_matrix.shape #문서id X token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09525c",
   "metadata": {},
   "source": [
    "### TfidfVectorizer로 적용하면, feature name이 일부변경되는 문제\n",
    "- 예를들어, 토큰값 nt950xdz-g58aw 값이 g58aw,nt950x로 분리...\n",
    "- 원인 : 사이킷런 내부에서 지정한 단어사전으로 만들어서\n",
    "- 해결 : TfidfVectorizer의 tokenizer옵션 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_col = vect2.get_feature_names() \n",
    "tfidf_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf-idf적용한 결과 df로 생성 \n",
    "\n",
    "tfidv_df = pd.DataFrame(tfvect_matrix.toarray(), index = list(tmp['id']), columns = sorted(tfidf_col))\n",
    "tfidv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292529ca",
   "metadata": {},
   "source": [
    "## 4. 검색어(query) 테스트\n",
    "\n",
    "- 입력한 키워드 토큰화 리스트 : q_token\n",
    "- reverted_index로 입력한 quey가 있는 문서id 리스트 리턴  \n",
    "- 문서들의 교집합을 찾음 : q_documents \n",
    "<br><br>\n",
    "- 교집합 문서들의 name : search_dc\n",
    "- 교집합 문서들의 td-idf(score) : search_tf\n",
    "- search_dc와 search_tf merge : search\n",
    "- score기준 내림차순 정렬 \n",
    "<br><br>\n",
    "- 최종결과 response message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"아이폰 중고폰\"\n",
    "#입력한 키워드 토큰화 \n",
    "token_list = tokenizer(q)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_dict 그대로 사용한 ver \n",
    "\n",
    "# query가 들어있는 문서id\n",
    "q_documents=[]\n",
    "for tk in token_list:\n",
    "    q_documents.append(set(index_dict[tk])) \n",
    "print(q_documents)\n",
    "\n",
    "# 문서들의 교집합 \n",
    "query_documents = list(q_documents[0].intersection(*q_documents))\n",
    "print(query_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7fe7e",
   "metadata": {},
   "source": [
    "### token에 없는 키워드로 검색했을때 예외사항 발생문제 \n",
    "- 키워드로 검색했는데 token에 없는 경우\n",
    "- 키워드로 검색한 토큰리스트 중에 일부만 token에 있는 경우도 있을 수 있어서 처리 ->new_token_list생성\n",
    "- 문서들의 교집합 없을 수도 있어서 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0831 : ndex_dict 파일로 바꾼 ver - 없는 키워드 입력 고려 \n",
    "\n",
    "search_token =index_df[index_df['token'].isin(token_list)]\n",
    "#print(search_token)\n",
    "\n",
    "new_token_list = list(search_token['token'])\n",
    "print(new_token_list) \n",
    "\n",
    "if len(new_token_list) == 0:\n",
    "    print(\"없는 키워드\")\n",
    "\n",
    "q_documents=[]\n",
    "for docu_list in search_token['docu_list']:\n",
    "    q_documents.append(set(docu_list))\n",
    "\n",
    "# 문서들의 교집합 \n",
    "query_documents = list(q_documents[0].intersection(*q_documents))\n",
    "print(query_documents)\n",
    "\n",
    "if len(query_documents) == 0:\n",
    "    print(\"교집합없음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3a57f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#교집합 문서들의 id,name\n",
    "search_dc = tmp[tmp['id'].isin(query_documents)]\n",
    "search_dc=search_dc.set_index('id')\n",
    "search_dc\n",
    "\n",
    "#교집합 문서들에 대해서 tf-dif(score값)\n",
    "#tfidv_df.loc[query_documents] #교집합문서\n",
    "search_tf = tfidv_df.loc[query_documents][new_token_list] ## 여기에서 token_list에서 tokne에 없는게 있음 \n",
    "\n",
    "search_tf['score'] = search_tf.sum(axis=1)\n",
    "search_tf\n",
    "\n",
    "# search_dc와 search_tf join (by id)\n",
    "search=search_tf.join(search_dc,how='inner')\n",
    "search['pid']=search.index\n",
    "search.sort_values(by=['score'],ascending=[False],inplace=True) #score기준 정렬\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종결과 \n",
    "response = search[['pid','name','score']]\n",
    "response\n",
    "\n",
    "# response msg\n",
    "js = response.to_json(orient='records')\n",
    "res_data =json.loads(js)\n",
    "res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba74f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
